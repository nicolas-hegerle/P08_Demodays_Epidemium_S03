{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 08: Epidemium - Model training\n",
    "## Bloc nÂ°6 - Jedha - dsmft - Paris14\n",
    "### Joseph Abitbol & Nicolas Hegerle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports and function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Import the necessary libraries</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from train_func import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Define functions</ins>\n",
    "\n",
    "* construction of the dataframe requires that we shuffle it a bit before training the model to avoid batch<br>\n",
    "shuffle bias in which not all the target outcomes are distributed between train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little function to shuffle our inital dataframe\n",
    "def shuffle_dataframe(df, nb_shuffle):\n",
    "    for i in range(nb_shuffle):\n",
    "        df = df.sample(frac=1, random_state = 123)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and shuffle it\n",
    "df = pd.read_csv(\"src/train/train_img_data.csv\", index_col=[0])\n",
    "df = shuffle_dataframe(df, 10)\n",
    "print(f\"Shape of the df: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvNet = convnet(224,224,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets train some models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Train base models on all mixed cell types and split raw, red, blue and all sub-figures</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow applications used for transferlearning: keys = dir names used to save files, values = instances of the applications\n",
    "app_dir, app_instance = ('CN' , ConvNet)\n",
    "\n",
    "# level of layers we will free for model training: tl_dir = name used to save files, values = None implies we use the base model and only train prediction layer\n",
    "tl_dir, tl_pct = ('base', None)\n",
    "\n",
    "# cell types for which we want to train the model, cell_dir = name for files, None implies we use all img data\n",
    "cell_dir, cell_type = ('all', None)\n",
    "\n",
    "# format of the img used to filter data for training: raw => use only raw untransformed images; False => use red, blue and raw images\n",
    "img_format = [None, 'raw', 'red', 'blue']\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    "for img_type in img_format: \n",
    "\n",
    "    if img_type: # generate mask and filter dataframe on image_format\n",
    "        mask = df['img_format'] == img_type\n",
    "        data = df.loc[mask]\n",
    "\n",
    "    else:\n",
    "        img_type = 'rrb'\n",
    "        data = df\n",
    "\n",
    "    # generate the ImageDataGenerator flow from dataframe image generators from the dataframe\n",
    "    train_gen, val_gen = create_imgen(data)\n",
    "\n",
    "    print(f\"====Generated the img generators for {cell_dir} cell types and {img_type} sub-images====\")\n",
    "\n",
    "    # loop through the tf applications to train each model on each cell type\n",
    "        \n",
    "    # set paths to save checkpoints and tensorboard data\n",
    "    check_path = f\"model/{app_dir}_checkpoint/{cell_dir}_{img_type}_{app_dir}_{tl_dir}.hdf5\"\n",
    "    tb_path = f\"src/tf_logs/{app_dir}_tl_logs/{cell_dir}_{img_type}_{app_dir}_{tl_dir}\"\n",
    "    checkpoint, tensorboard = create_callbacks(check_path, tb_path)\n",
    "    model = app_instance\n",
    "    print(model.summary())\n",
    "\n",
    "    print(f\"\\n====Started training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "    best_model = train_model(model, train_gen, val_gen, checkpoint, tensorboard, loss = 'mae', learning_rate=0.05, epochs = 30)\n",
    "    clear_output(wait = True)\n",
    "\n",
    "    print(f\"\\n====Finished training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "    # generate predictions on train and val\n",
    "    path = \"src/pred_df/\"\n",
    "    dir = f\"{app_dir}_{tl_dir}_preds\"\n",
    "    file_names = [f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_train.csv\", f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_test.csv\"]\n",
    "\n",
    "    print(f\"\\n====Started generating predictions for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "    _, _ = generate_predictions(data, best_model, 30, train_gen, val_gen, save = True, path=path, dir = dir, file_names=file_names)\n",
    "\n",
    "    print(f\"\\n====Loop finished for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow applications used for transferlearning: keys = dir names used to save files, values = instances of the applications\n",
    "applications = {'Iv3' : InceptionV3, 'IRNv2' : InceptionResNetV2, 'DN201' : DenseNet201}\n",
    "\n",
    "# level of layers we will free for model training: tl_dir = name used to save files, values = None implies we use the base model and only train prediction layer\n",
    "tl_dir, tl_pct = ('base', None)\n",
    "\n",
    "# cell types for which we want to train the model, cell_dir = name for files, None implies we use all img data\n",
    "cell_dir, cell_type = ('all', None)\n",
    "\n",
    "# format of the img used to filter data for training: raw => use only raw untransformed images; False => use red, blue and raw images\n",
    "img_format = ['raw', 'red', 'blue']\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    "for img_type in img_format: \n",
    "\n",
    "    if img_type: # generate mask and filter dataframe on image_format\n",
    "        mask = df['img_format'] == img_type\n",
    "        data = df.loc[mask]\n",
    "\n",
    "    else:\n",
    "        img_type = 'rrb'\n",
    "        data = df\n",
    "\n",
    "    # generate the ImageDataGenerator flow from dataframe image generators from the dataframe\n",
    "    train_gen, val_gen = create_imgen(data)\n",
    "\n",
    "    print(f\"====Generated the img generators for {cell_dir} cell types and {img_type} sub-images====\")\n",
    "\n",
    "    # loop through the tf applications to train each model on each cell type\n",
    "\n",
    "    for app_dir, app_instance in applications.items():\n",
    "        \n",
    "        # instantiate the model (if free == None base model is trained\n",
    "        model = create_model(app_instance, free = tl_pct, activation = 'linear')\n",
    "        print(f\"\\n====Generated model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "        print(model.summary())\n",
    "\n",
    "        # set paths to save checkpoints and tensorboard data\n",
    "        check_path = f\"model/{app_dir}_checkpoint/{cell_dir}_{img_type}_{app_dir}_{tl_dir}.hdf5\"\n",
    "        tb_path = f\"src/tf_logs/{app_dir}_tl_logs/{cell_dir}_{img_type}_{app_dir}_{tl_dir}\"\n",
    "        checkpoint, tensorboard = create_callbacks(check_path, tb_path)\n",
    "\n",
    "        print(f\"\\n====Started training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "        best_model = train_model(model, train_gen, val_gen, checkpoint, tensorboard, loss = 'mae', learning_rate=0.05, epochs = 30)\n",
    "        clear_output(wait = True)\n",
    "\n",
    "        print(f\"\\n====Finished training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "        # generate predictions on train and val\n",
    "        path = \"src/pred_df/\"\n",
    "        dir = f\"{app_dir}_{tl_dir}_preds\"\n",
    "        file_names = [f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_train.csv\", f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_test.csv\"]\n",
    "\n",
    "        print(f\"\\n====Started generating predictions for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "        _, _ = generate_predictions(data, best_model, 30, train_gen, val_gen, save = True, path=path, dir = dir, file_names=file_names)\n",
    "\n",
    "        print(f\"\\n====Loop finished for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow applications used for transferlearning: keys = dir names used to save files, values = instances of the applications\n",
    "applications = {'Iv3' : InceptionV3, 'IRNv2' : InceptionResNetV2, 'DN201' : DenseNet201}\n",
    "\n",
    "# level of layers we will free for model training: tl_dir = name used to save files, values = 20 implies we free 20% of the model for training\n",
    "tl_dir, tl_pct = ('20pct', 20)\n",
    "\n",
    "# cell types for which we have imgs available: keys = dir names used to save files, velues = cell type names used to subselect the data\n",
    "cell_types = {\n",
    "        'all' : False,\n",
    "        'ci1' : 'cell_infla_1',\n",
    "        'ci2' : 'cell_infla_2',\n",
    "        'ci4' : 'cell_infla_4',\n",
    "        'cti5' : 'cell_tum_infla_3',\n",
    "        'cti6' : 'cell_tum_infla_6',\n",
    "        'st' : 'seg_tissu'\n",
    "            }\n",
    "\n",
    "# format of the img used to filter data for training: raw => use only raw untransformed images; False => use red, blue and raw images\n",
    "img_format = [None, 'raw', 'red', 'blue']\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    "for cell_dir, cell_type in cell_types.items():\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    if cell_type: # if cell type is not False create a mask to filter the cell type\n",
    "        mask_1 = df['raw_img_dir'] == cell_type\n",
    "\n",
    "    else: # else generate a mask to keep the entire dataframe\n",
    "        mask_1 = pd.Series([True for i in range(df.shape[0])])\n",
    "    \n",
    "    # loop through the image types to train on raw images (raw) only or raw with blue and red filtered images (False)\n",
    "    # generate a second mask to filter the dataframe based on cell type and image type\n",
    "\n",
    "    for img_type in img_format: \n",
    "\n",
    "        if cell_type == 'seg_tissu' and img_type: # no filtered images for seg_tissu so skip this step for raw seg_tissu\n",
    "            continue\n",
    "\n",
    "        elif img_type: # generate 2nd mask and filter dataframe on cell_type and image_format\n",
    "            mask_2 = df['img_format'] == img_type\n",
    "            data = df.loc[mask_1 & mask_2]\n",
    "\n",
    "        else:\n",
    "            data = df.loc[mask_1]\n",
    "            img_type = 'rrb'\n",
    "\n",
    "        # generate the ImageDataGenerator flow from dataframe image generators from the dataframe\n",
    "        train_gen, val_gen = create_imgen(data)\n",
    "\n",
    "        print(f\"====Generated the img generators for {img_type}, {cell_dir}====\")\n",
    "\n",
    "        # loop through the tf applications to train each model on each cell type\n",
    "\n",
    "        for app_dir, app_instance in applications.items():\n",
    "\n",
    "            # instantiate the model if free == None base model is trained\n",
    "            model = create_model(app_instance, free = tl_pct, activation = 'linear')\n",
    "            print(f\"\\n====Generated model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "            print(model.summary())\n",
    "\n",
    "            # set paths to save checkpoints and tensorboard data\n",
    "            check_path = f\"model/{app_dir}_checkpoint/{cell_dir}_{img_type}_{app_dir}_{tl_dir}.hdf5\"\n",
    "            tb_path = f\"src/tf_logs/{app_dir}_tl_logs/{cell_dir}_{img_type}_{app_dir}_{tl_dir}\"\n",
    "            checkpoint, tensorboard = create_callbacks(check_path, tb_path)\n",
    "\n",
    "            print(f\"\\n====Started training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            best_model = train_model(model, train_gen, val_gen, checkpoint, tensorboard, loss = 'mae', epochs = 70, learning_rate=0.05)\n",
    "            clear_output(wait = True)\n",
    "\n",
    "            print(f\"\\n====Finished training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            # generate predictions on train and val\n",
    "            path = \"src/pred_df/\"\n",
    "            dir = f\"{app_dir}_{tl_dir}_preds\"\n",
    "            file_names = [f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_train.csv\", f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_test.csv\"]\n",
    "\n",
    "            print(f\"\\n====Started generating predictions for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            _, _ = generate_predictions(data, best_model, 30, train_gen, val_gen, save = True, path=path, dir = dir, file_names=file_names)\n",
    "        \n",
    "            print(f\"\\n====Loop finshed for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow applications used for transferlearning: keys = dir names used to save files, values = instances of the applications\n",
    "applications = {'Iv3' : InceptionV3, 'IRNv2' : InceptionResNetV2, 'DN201' : DenseNet201}\n",
    "\n",
    "# level of layers we will free for model training: tl_dir = name used to save files, values = 20 implies we free 20% of the model for training\n",
    "tl_dir, tl_pct = ('30pct', 30)\n",
    "\n",
    "# cell types for which we have imgs available: keys = dir names used to save files, velues = cell type names used to subselect the data\n",
    "cell_types = {\n",
    "        'all' : False,\n",
    "        'ci1' : 'cell_infla_1',\n",
    "        'ci2' : 'cell_infla_2',\n",
    "        'ci4' : 'cell_infla_4',\n",
    "        'cti5' : 'cell_tum_infla_3',\n",
    "        'cti6' : 'cell_tum_infla_6',\n",
    "        'st' : 'seg_tissu'\n",
    "            }\n",
    "\n",
    "# format of the img used to filter data for training: raw => use only raw untransformed images; False => use red, blue and raw images\n",
    "img_format = [None, 'raw', 'red', 'blue']\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    "for cell_dir, cell_type in cell_types.items():\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    if cell_type: # if cell type is not False create a mask to filter the cell type\n",
    "        mask_1 = df['raw_img_dir'] == cell_type\n",
    "\n",
    "    else: # else generate a mask to keep the entire dataframe\n",
    "        mask_1 = pd.Series([True for i in range(df.shape[0])])\n",
    "    \n",
    "    # loop through the image types to train on raw images (raw) only or raw with blue and red filtered images (False)\n",
    "    # generate a second mask to filter the dataframe based on cell type and image type\n",
    "\n",
    "    for img_type in img_format: \n",
    "\n",
    "        if cell_type == 'seg_tissu' and img_type: # no filtered images for seg_tissu so skip this step for raw seg_tissu\n",
    "            continue\n",
    "\n",
    "        elif img_type: # generate 2nd mask and filter dataframe on cell_type and image_format\n",
    "            mask_2 = df['img_format'] == img_type\n",
    "            data = df.loc[mask_1 & mask_2]\n",
    "\n",
    "        else:\n",
    "            data = df.loc[mask_1]\n",
    "            img_type = 'rrb'\n",
    "\n",
    "        # generate the ImageDataGenerator flow from dataframe image generators from the dataframe\n",
    "        train_gen, val_gen = create_imgen(data)\n",
    "\n",
    "        print(f\"====Generated the img generators for {img_type}, {cell_dir}====\")\n",
    "\n",
    "        # loop through the tf applications to train each model on each cell type\n",
    "\n",
    "        for app_dir, app_instance in applications.items():\n",
    "\n",
    "            # instantiate the model if free == None base model is trained\n",
    "            model = create_model(app_instance, free = tl_pct, activation = 'linear')\n",
    "            print(f\"\\n====Generated model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "            print(model.summary())\n",
    "\n",
    "            # set paths to save checkpoints and tensorboard data\n",
    "            check_path = f\"model/{app_dir}_checkpoint/{cell_dir}_{img_type}_{app_dir}_{tl_dir}.hdf5\"\n",
    "            tb_path = f\"src/tf_logs/{app_dir}_tl_logs/{cell_dir}_{img_type}_{app_dir}_{tl_dir}\"\n",
    "            checkpoint, tensorboard = create_callbacks(check_path, tb_path)\n",
    "\n",
    "            print(f\"\\n====Started training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            best_model = train_model(model, train_gen, val_gen, checkpoint, tensorboard, loss = 'mae', epochs = 70, learning_rate=1)\n",
    "            clear_output(wait = True)\n",
    "\n",
    "            print(f\"\\n====Finished training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            # generate predictions on train and val\n",
    "            path = \"src/pred_df/\"\n",
    "            dir = f\"{app_dir}_{tl_dir}_preds\"\n",
    "            file_names = [f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_train.csv\", f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_test.csv\"]\n",
    "\n",
    "            print(f\"\\n====Started generating predictions for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            _, _ = generate_predictions(data, best_model, 30, train_gen, val_gen, save = True, path=path, dir = dir, file_names=file_names)\n",
    "        \n",
    "            print(f\"\\n====Loop finshed for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries and lists used for model training\n",
    "\n",
    "# tensorflow applications used for transferlearning: keys = dir names used to save files, values = instances of the applications\n",
    "applications = {\n",
    "        'Iv3' : InceptionV3,\n",
    "        'IRNv2' : InceptionResNetV2,\n",
    "        'DN201' : DenseNet201,\n",
    "        'CN' : ConvNet\n",
    "            }\n",
    "\n",
    "# level of layers we will free for model training: keys = dir names used to save files, values = % of the layers we will free\n",
    "tl_free_layers = {\n",
    "        'base' : None,\n",
    "        '20pct' : 20,\n",
    "        '30pct' : 30\n",
    "            }\n",
    "\n",
    "# cell types for which we have imgs available: keys = dir names used to save files, values = cell type names used to subselect the data\n",
    "cell_types = {\n",
    "        'all' : False,\n",
    "        'ci1' : 'cell_infla_1',\n",
    "        'ci2' : 'cell_infla_2',\n",
    "        'ci4' : 'cell_infla_4',\n",
    "        'cti5' : 'cell_tum_infla_3',\n",
    "        'cti6' : 'cell_tum_infla_6',\n",
    "        'st' : 'seg_tissu'\n",
    "            }\n",
    "\n",
    "# format of the img used to filter data for training: raw => use only raw untransformed images; False => use red, blue and raw images\n",
    "img_format = [\n",
    "        False,\n",
    "        'raw',\n",
    "        'red',\n",
    "        'blue'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    "for cell_dir, cell_type in cell_types.items():\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    if cell_type: # if cell type is not False create a mask to filter the cell type\n",
    "        mask_1 = df['raw_img_dir'] == cell_type\n",
    "\n",
    "    else: # else generate a mask to keep the entire dataframe\n",
    "        mask_1 = pd.Series([True for i in range(df.shape[0])])\n",
    "    \n",
    "    # loop through the image types to train on raw images (raw) only or raw with blue and red filtered images (False)\n",
    "    # generate a second mask to filter the dataframe based on cell type and image type\n",
    "\n",
    "    for img_type in img_format: \n",
    "\n",
    "        if cell_type == 'seg_tissu' and img_type: # no filtered images for seg_tissu so skip this step for raw seg_tissu\n",
    "            continue\n",
    "\n",
    "        elif img_type: # generate 2nd mask and filter dataframe on cell_type and image_format\n",
    "            mask_2 = df['img_format'] == img_type\n",
    "            data = df.loc[mask_1 & mask_2]\n",
    "\n",
    "        else:\n",
    "            data = df.loc[mask_1]\n",
    "            img_type = 'rrb'\n",
    "\n",
    "        # generate the ImageDataGenerator flow from dataframe image generators from the dataframe\n",
    "        train_gen, val_gen = create_imgen(data)\n",
    "\n",
    "        print(f\"====Generated the img generators for {img_type}, {cell_dir}====\")\n",
    "\n",
    "        # loop through the tf applications to train each model on each cell type\n",
    "\n",
    "        for app_dir, app_instance in applications.items():\n",
    "            \n",
    "            # loop through the desired % of free layers we want for each model\n",
    "\n",
    "            for tl_dir, tl_pct in tl_free_layers.items():\n",
    "                # instantiate the model if free == None base model is trained\n",
    "                model = create_model(app_instance, free = tl_pct, activation = 'linear')\n",
    "                print(f\"\\n====Generated model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "                print(model.summary())\n",
    "\n",
    "                # set paths to save checkpoints and tensorboard data\n",
    "                check_path = f\"model/{app_dir}_checkpoint/{cell_dir}_{img_type}_{app_dir}_{tl_dir}.hdf5\"\n",
    "                tb_path = f\"src/tf_logs/{app_dir}_tl_logs/{cell_dir}_{img_type}_{app_dir}_{tl_dir}\"\n",
    "                checkpoint, tensorboard = create_callbacks(check_path, tb_path)\n",
    "\n",
    "                print(f\"\\n====Started training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "                best_model = train_model(model, train_gen, val_gen, checkpoint, tensorboard, loss = 'mae', epochs = 70)\n",
    "                clear_output(wait = True)\n",
    "\n",
    "                print(f\"\\n====Finished training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "                # generate predictions on train and val\n",
    "                path = \"src/pred_df/\"\n",
    "                dir = f\"{app_dir}_{tl_dir}_preds\"\n",
    "                file_names = [f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_train.csv\", f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_test.csv\"]\n",
    "\n",
    "                print(f\"\\n====Started generating predictions for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "                _, _ = generate_predictions(data, best_model, 30, train_gen, val_gen, save = True, path=path, dir = dir, file_names=file_names)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3bcc9d6d5689eb93fd607a819b4d17597ccd318a9046f8daab5c08e0a354b76"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
