{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 08: Epidemium - Model training\n",
    "## Bloc n°6 - Jedha - dsmft - Paris14\n",
    "### Joseph Abitbol & Nicolas Hegerle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports and function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Import the necessary libraries</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from train_func import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Define functions</ins>\n",
    "\n",
    "* construction of the dataframe requires that we shuffle it a bit before training the model to avoid batch<br>\n",
    "shuffle bias in which not all the target outcomes are distributed between train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little function to shuffle our inital dataframe\n",
    "def shuffle_dataframe(df, nb_shuffle):\n",
    "    for i in range(nb_shuffle):\n",
    "        df = df.sample(frac=1, random_state = 123)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the df: (2920, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>set</th>\n",
       "      <th>img_file</th>\n",
       "      <th>raw_img_dir</th>\n",
       "      <th>img_rename</th>\n",
       "      <th>img_format</th>\n",
       "      <th>oms</th>\n",
       "      <th>sexe (0=f 1=m)</th>\n",
       "      <th>ddn</th>\n",
       "      <th>date biopsie</th>\n",
       "      <th>...</th>\n",
       "      <th>localisation</th>\n",
       "      <th>rnascope</th>\n",
       "      <th>t</th>\n",
       "      <th>n</th>\n",
       "      <th>m</th>\n",
       "      <th>tabac</th>\n",
       "      <th>alcool</th>\n",
       "      <th>data</th>\n",
       "      <th>os</th>\n",
       "      <th>img_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b41668</td>\n",
       "      <td>train</td>\n",
       "      <td>b41668_[18952,52941]_composite_image.jpg</td>\n",
       "      <td>cell_infla_2</td>\n",
       "      <td>raw_cell_infla_2_b41668_[18952,52941]_composit...</td>\n",
       "      <td>raw</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1941-10-26</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td>...</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Image + clinical</td>\n",
       "      <td>46</td>\n",
       "      <td>src/sorted_img/train/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b5e396</td>\n",
       "      <td>train</td>\n",
       "      <td>b5e396_[13085,39442]_composite_image.jpg</td>\n",
       "      <td>cell_infla_2</td>\n",
       "      <td>red_cell_infla_2_b5e396_[13085,39442]_composit...</td>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1934-01-08</td>\n",
       "      <td>2013-04-24</td>\n",
       "      <td>...</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Image + clinical</td>\n",
       "      <td>12</td>\n",
       "      <td>src/sorted_img/train/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afdc1c</td>\n",
       "      <td>train</td>\n",
       "      <td>afdc1c_[11130,46985]_composite_image.jpg</td>\n",
       "      <td>cell_tum_infla_6</td>\n",
       "      <td>raw_cell_tum_infla_6_afdc1c_[11130,46985]_comp...</td>\n",
       "      <td>raw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1958-11-04</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>...</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Image + clinical</td>\n",
       "      <td>70</td>\n",
       "      <td>src/sorted_img/train/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aea82d</td>\n",
       "      <td>train</td>\n",
       "      <td>aea82d_[14222,49073]_composite_image.jpg</td>\n",
       "      <td>cell_infla_5</td>\n",
       "      <td>red_cell_infla_5_aea82d_[14222,49073]_composit...</td>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1964-05-16</td>\n",
       "      <td>2012-12-21</td>\n",
       "      <td>...</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Image + clinical</td>\n",
       "      <td>75</td>\n",
       "      <td>src/sorted_img/train/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a801cb</td>\n",
       "      <td>train</td>\n",
       "      <td>a801cb_[13408,36249]_image_with_tissue_seg.jpg</td>\n",
       "      <td>seg_tissu</td>\n",
       "      <td>raw_seg_tissu_a801cb_[13408,36249]_image_with_...</td>\n",
       "      <td>raw</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1939-02-27</td>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>...</td>\n",
       "      <td>Oropharynx</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Image + clinical</td>\n",
       "      <td>34</td>\n",
       "      <td>src/sorted_img/train/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    set                                        img_file  \\\n",
       "0  b41668  train        b41668_[18952,52941]_composite_image.jpg   \n",
       "1  b5e396  train        b5e396_[13085,39442]_composite_image.jpg   \n",
       "2  afdc1c  train        afdc1c_[11130,46985]_composite_image.jpg   \n",
       "3  aea82d  train        aea82d_[14222,49073]_composite_image.jpg   \n",
       "4  a801cb  train  a801cb_[13408,36249]_image_with_tissue_seg.jpg   \n",
       "\n",
       "        raw_img_dir                                         img_rename  \\\n",
       "0      cell_infla_2  raw_cell_infla_2_b41668_[18952,52941]_composit...   \n",
       "1      cell_infla_2  red_cell_infla_2_b5e396_[13085,39442]_composit...   \n",
       "2  cell_tum_infla_6  raw_cell_tum_infla_6_afdc1c_[11130,46985]_comp...   \n",
       "3      cell_infla_5  red_cell_infla_5_aea82d_[14222,49073]_composit...   \n",
       "4         seg_tissu  raw_seg_tissu_a801cb_[13408,36249]_image_with_...   \n",
       "\n",
       "  img_format  oms  sexe (0=f 1=m)         ddn date biopsie  ...  localisation  \\\n",
       "0        raw    1               1  1941-10-26   2013-04-11  ...    Oropharynx   \n",
       "1        red    2               1  1934-01-08   2013-04-24  ...    Oropharynx   \n",
       "2        raw    0               0  1958-11-04   2013-02-25  ...    Oropharynx   \n",
       "3        red    1               0  1964-05-16   2012-12-21  ...    Oropharynx   \n",
       "4        raw    1               1  1939-02-27   2013-07-29  ...    Oropharynx   \n",
       "\n",
       "   rnascope  t   n  m  tabac alcool              data  os  \\\n",
       "0         2  4   3  1      3      1  Image + clinical  46   \n",
       "1         1  4   1  0      3      1  Image + clinical  12   \n",
       "2         2  2  2b  0      0      1  Image + clinical  70   \n",
       "3         0  4   2  0      1      1  Image + clinical  75   \n",
       "4         1  4  2b  0      0      1  Image + clinical  34   \n",
       "\n",
       "                 img_dir  \n",
       "0  src/sorted_img/train/  \n",
       "1  src/sorted_img/train/  \n",
       "2  src/sorted_img/train/  \n",
       "3  src/sorted_img/train/  \n",
       "4  src/sorted_img/train/  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset and shuffle it\n",
    "df = pd.read_csv(\"src/train/train_img_data.csv\", index_col=[0])\n",
    "df = shuffle_dataframe(df, 10)\n",
    "print(f\"Shape of the df: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Train ConvNet</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow applications used for transferlearning: keys = dir names used to save files, values = instances of the applications\n",
    "app_dir = 'CN'\n",
    "\n",
    "# level of layers we will free for model training: tl_dir = name used to save files, values = None implies we use the base model and only train prediction layer\n",
    "tl_dir, tl_pct = ('base', None)\n",
    "\n",
    "# cell types for which we have imgs available: keys = dir names used to save files, velues = cell type names used to subselect the data\n",
    "cell_types = {\n",
    "        'all' : False,\n",
    "        'ci1' : 'cell_infla_1',\n",
    "        'ci2' : 'cell_infla_2',\n",
    "        'ci4' : 'cell_infla_4',\n",
    "        'cti5' : 'cell_tum_infla_3',\n",
    "        'cti6' : 'cell_tum_infla_6',\n",
    "        'st' : 'seg_tissu'\n",
    "            }\n",
    "\n",
    "# format of the img used to filter data for training: raw => use only raw untransformed images; False => use red, blue and raw images\n",
    "img_format = [None, 'raw', 'red', 'blue']\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    "for cell_dir, cell_type in cell_types.items():\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    if cell_type: # if cell type is not False create a mask to filter the cell type\n",
    "        mask_1 = df['raw_img_dir'] == cell_type\n",
    "\n",
    "    else: # else generate a mask to keep the entire dataframe\n",
    "        mask_1 = pd.Series([True for i in range(df.shape[0])])\n",
    "    \n",
    "    # loop through the image types to train on raw images (raw) only or raw with blue and red filtered images (False)\n",
    "    # generate a second mask to filter the dataframe based on cell type and image type\n",
    "\n",
    "    for img_type in img_format: \n",
    "\n",
    "        if cell_type == 'seg_tissu' and img_type: # no filtered images for seg_tissu so skip this step for raw seg_tissu\n",
    "            continue\n",
    "\n",
    "        elif img_type: # generate 2nd mask and filter dataframe on cell_type and image_format\n",
    "            mask_2 = df['img_format'] == img_type\n",
    "            data = df.loc[mask_1 & mask_2]\n",
    "\n",
    "        else:\n",
    "            data = df.loc[mask_1]\n",
    "            img_type = 'rrb'\n",
    "\n",
    "        # generate the ImageDataGenerator flow from dataframe image generators from the dataframe\n",
    "        train_gen, val_gen = create_imgen(data)\n",
    "\n",
    "        print(f\"====Generated the img generators for {img_type}, {cell_dir}====\")\n",
    "\n",
    "        # loop through the tf applications to train each model on each cell type\n",
    "\n",
    "        # instantiate the model if free == None base model is trained\n",
    "        model = convnet(224,224,3)\n",
    "        print(f\"\\n====Generated model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "        print(model.summary())\n",
    "\n",
    "        # set paths to save checkpoints and tensorboard data\n",
    "        check_path = f\"model/{app_dir}_checkpoint/{cell_dir}_{img_type}_{app_dir}_{tl_dir}.hdf5\"\n",
    "        tb_path = f\"src/tf_logs/{app_dir}_tl_logs/{cell_dir}_{img_type}_{app_dir}_{tl_dir}\"\n",
    "        checkpoint, tensorboard = create_callbacks(check_path, tb_path)\n",
    "\n",
    "        print(f\"\\n====Started training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "        best_model = train_model(model, train_gen, val_gen, checkpoint, tensorboard, loss = 'mae', epochs = 50, learning_rate=0.05)\n",
    "        clear_output(wait = True)\n",
    "\n",
    "        print(f\"\\n====Finished training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "        # generate predictions on train and val\n",
    "        path = \"src/pred_df/\"\n",
    "        dir = f\"{app_dir}_{tl_dir}_preds\"\n",
    "        file_names = [f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_train.csv\", f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_test.csv\"]\n",
    "\n",
    "        print(f\"\\n====Started generating predictions for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "        _, _ = generate_predictions(data, best_model, 30, train_gen, val_gen, save = True, path=path, dir = dir, file_names=file_names)\n",
    "    \n",
    "        print(f\"\\n====Loop finshed for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Train base models</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow applications used for transferlearning: keys = dir names used to save files, values = instances of the applications\n",
    "applications = {'Iv3' : InceptionV3, 'IRNv2' : InceptionResNetV2, 'DN201' : DenseNet201}\n",
    "\n",
    "# level of layers we will free for model training: tl_dir = name used to save files, values = 20 implies we free 20% of the model for training\n",
    "tl_dir, tl_pct = ('base', None)\n",
    "\n",
    "# cell types for which we have imgs available: keys = dir names used to save files, velues = cell type names used to subselect the data\n",
    "cell_types = {\n",
    "        'all' : False,\n",
    "        'ci1' : 'cell_infla_1',\n",
    "        'ci2' : 'cell_infla_2',\n",
    "        'ci4' : 'cell_infla_4',\n",
    "        'cti5' : 'cell_tum_infla_3',\n",
    "        'cti6' : 'cell_tum_infla_6',\n",
    "        'st' : 'seg_tissu'\n",
    "            }\n",
    "\n",
    "# format of the img used to filter data for training: raw => use only raw untransformed images; False => use red, blue and raw images\n",
    "img_format = [None, 'raw', 'red', 'blue']\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    "for cell_dir, cell_type in cell_types.items():\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    if cell_type: # if cell type is not False create a mask to filter the cell type\n",
    "        mask_1 = df['raw_img_dir'] == cell_type\n",
    "\n",
    "    else: # else generate a mask to keep the entire dataframe\n",
    "        mask_1 = pd.Series([True for i in range(df.shape[0])])\n",
    "    \n",
    "    # loop through the image types to train on raw images (raw) only or raw with blue and red filtered images (False)\n",
    "    # generate a second mask to filter the dataframe based on cell type and image type\n",
    "\n",
    "    for img_type in img_format: \n",
    "\n",
    "        if cell_type == 'seg_tissu' and img_type: # no filtered images for seg_tissu so skip this step for raw seg_tissu\n",
    "            continue\n",
    "\n",
    "        elif img_type: # generate 2nd mask and filter dataframe on cell_type and image_format\n",
    "            mask_2 = df['img_format'] == img_type\n",
    "            data = df.loc[mask_1 & mask_2]\n",
    "\n",
    "        else:\n",
    "            data = df.loc[mask_1]\n",
    "            img_type = 'rrb'\n",
    "\n",
    "        # generate the ImageDataGenerator flow from dataframe image generators from the dataframe\n",
    "        train_gen, val_gen = create_imgen(data)\n",
    "\n",
    "        print(f\"====Generated the img generators for {img_type}, {cell_dir}====\")\n",
    "\n",
    "        # loop through the tf applications to train each model on each cell type\n",
    "\n",
    "        for app_dir, app_instance in applications.items():\n",
    "\n",
    "            # instantiate the model if free == None base model is trained\n",
    "            model = create_model(app_instance, free = tl_pct, activation = 'linear')\n",
    "            print(f\"\\n====Generated model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "            print(model.summary())\n",
    "\n",
    "            # set paths to save checkpoints and tensorboard data\n",
    "            check_path = f\"model/{app_dir}_checkpoint/{cell_dir}_{img_type}_{app_dir}_{tl_dir}.hdf5\"\n",
    "            tb_path = f\"src/tf_logs/{app_dir}_tl_logs/{cell_dir}_{img_type}_{app_dir}_{tl_dir}\"\n",
    "            checkpoint, tensorboard = create_callbacks(check_path, tb_path)\n",
    "\n",
    "            print(f\"\\n====Started training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            best_model = train_model(model, train_gen, val_gen, checkpoint, tensorboard, loss = 'mae', epochs = 30, learning_rate=0.05)\n",
    "            clear_output(wait = True)\n",
    "\n",
    "            print(f\"\\n====Finished training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            # generate predictions on train and val\n",
    "            path = \"src/pred_df/\"\n",
    "            dir = f\"{app_dir}_{tl_dir}_preds\"\n",
    "            file_names = [f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_train.csv\", f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_test.csv\"]\n",
    "\n",
    "            print(f\"\\n====Started generating predictions for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            _, _ = generate_predictions(data, best_model, 30, train_gen, val_gen, save = True, path=path, dir = dir, file_names=file_names)\n",
    "        \n",
    "            print(f\"\\n====Loop finshed for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Train models with 20% layers freed for training</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow applications used for transferlearning: keys = dir names used to save files, values = instances of the applications\n",
    "applications = {'Iv3' : InceptionV3, 'IRNv2' : InceptionResNetV2, 'DN201' : DenseNet201}\n",
    "\n",
    "# level of layers we will free for model training: tl_dir = name used to save files, values = 20 implies we free 20% of the model for training\n",
    "tl_dir, tl_pct = ('20pct', 20)\n",
    "\n",
    "# cell types for which we have imgs available: keys = dir names used to save files, velues = cell type names used to subselect the data\n",
    "cell_types = {\n",
    "        'all' : False,\n",
    "        'ci1' : 'cell_infla_1',\n",
    "        'ci2' : 'cell_infla_2',\n",
    "        'ci4' : 'cell_infla_4',\n",
    "        'cti5' : 'cell_tum_infla_3',\n",
    "        'cti6' : 'cell_tum_infla_6',\n",
    "        'st' : 'seg_tissu'\n",
    "            }\n",
    "\n",
    "# format of the img used to filter data for training: raw => use only raw untransformed images; False => use red, blue and raw images\n",
    "img_format = [None, 'raw', 'red', 'blue']\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    " # loop through the different cell types to train on all images (False) or on each individual cell_type\n",
    " # genrate a mask to filter the dataframe\n",
    "\n",
    "for cell_dir, cell_type in cell_types.items():\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    if cell_type: # if cell type is not False create a mask to filter the cell type\n",
    "        mask_1 = df['raw_img_dir'] == cell_type\n",
    "\n",
    "    else: # else generate a mask to keep the entire dataframe\n",
    "        mask_1 = pd.Series([True for i in range(df.shape[0])])\n",
    "    \n",
    "    # loop through the image types to train on raw images (raw) only or raw with blue and red filtered images (False)\n",
    "    # generate a second mask to filter the dataframe based on cell type and image type\n",
    "\n",
    "    for img_type in img_format: \n",
    "\n",
    "        if cell_type == 'seg_tissu' and img_type: # no filtered images for seg_tissu so skip this step for raw seg_tissu\n",
    "            continue\n",
    "\n",
    "        elif img_type: # generate 2nd mask and filter dataframe on cell_type and image_format\n",
    "            mask_2 = df['img_format'] == img_type\n",
    "            data = df.loc[mask_1 & mask_2]\n",
    "\n",
    "        else:\n",
    "            data = df.loc[mask_1]\n",
    "            img_type = 'rrb'\n",
    "\n",
    "        # generate the ImageDataGenerator flow from dataframe image generators from the dataframe\n",
    "        train_gen, val_gen = create_imgen(data)\n",
    "\n",
    "        print(f\"====Generated the img generators for {img_type}, {cell_dir}====\")\n",
    "\n",
    "        # loop through the tf applications to train each model on each cell type\n",
    "\n",
    "        for app_dir, app_instance in applications.items():\n",
    "\n",
    "            # instantiate the model if free == None base model is trained\n",
    "            model = create_model(app_instance, free = tl_pct, activation = 'linear')\n",
    "            print(f\"\\n====Generated model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "            print(model.summary())\n",
    "\n",
    "            # set paths to save checkpoints and tensorboard data\n",
    "            check_path = f\"model/{app_dir}_checkpoint/{cell_dir}_{img_type}_{app_dir}_{tl_dir}.hdf5\"\n",
    "            tb_path = f\"src/tf_logs/{app_dir}_tl_logs/{cell_dir}_{img_type}_{app_dir}_{tl_dir}\"\n",
    "            checkpoint, tensorboard = create_callbacks(check_path, tb_path)\n",
    "\n",
    "            print(f\"\\n====Started training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            best_model = train_model(model, train_gen, val_gen, checkpoint, tensorboard, loss = 'mae', epochs = 70, learning_rate=0.05)\n",
    "            clear_output(wait = True)\n",
    "\n",
    "            print(f\"\\n====Finished training model for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            # generate predictions on train and val\n",
    "            path = \"src/pred_df/\"\n",
    "            dir = f\"{app_dir}_{tl_dir}_preds\"\n",
    "            file_names = [f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_train.csv\", f\"{cell_dir}_{img_type}_{app_dir}_{tl_dir}_test.csv\"]\n",
    "\n",
    "            print(f\"\\n====Started generating predictions for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")\n",
    "\n",
    "            _, _ = generate_predictions(data, best_model, 30, train_gen, val_gen, save = True, path=path, dir = dir, file_names=file_names)\n",
    "        \n",
    "            print(f\"\\n====Loop finshed for {app_dir}, {tl_dir}, {img_type}, {cell_dir}====\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3bcc9d6d5689eb93fd607a819b4d17597ccd318a9046f8daab5c08e0a354b76"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
